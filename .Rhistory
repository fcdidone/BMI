modelFit <- train(type ~.,data=training, method="glm")
modelFit
modelFit <- train(type ~.,data=training, method="glm")
install.packages('caret', dependencies = TRUE)
install.packages("caret", dependencies = TRUE)
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
set.seed(32343)
modelFit <- train(type ~.,data=training, method="glm")
modelFit$finalModel
predictions <- predict(modelFit,newdata=testing)
predictions
confusionMatrix(predictions,testing$type)
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
dim(training)
folds <- createFolds(y=spam$type,k=10,
list=TRUE,returnTrain=TRUE)
sapply(folds,length)
folds[[1]][1:10]
folds
set.seed(32323)
folds <- createFolds(y=spam$type,k=10,
list=TRUE,returnTrain=FALSE)
sapply(folds,length)
folds[[1]][1:10]
folds <- createResample(y=spam$type,times=10,
list=TRUE)
sapply(folds,length)
sapply(folds,mean)
set.seed(32323)
tme <- 1:1000
folds <- createTimeSlices(y=tme,initialWindow=20,
horizon=10)
names(folds)
folds$test[[1]]
folds$test[[1]]
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
modelFit <- train(type ~.,data=training, method="glm")
args(train.default)
args(trainControl)
set.seed(1235)
modelFit3 <- train(type ~.,data=training, method="glm")
library(ISLR); library(ggplot2); library(caret); library(gridExtra);
install.packages("ISLR")
library(ISLR); library(ggplot2); library(caret); library(gridExtra);
data(Wage)
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training); dim(testing)
featurePlot(x=training[,c("age","education","jobclass")],
y = training$wage,
plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,colour=jobclass,data=training)
qq <- qplot(age,wage,colour=education,data=training)
qq +  geom_smooth(method='lm',formula=y~x)
cutWage <- cut2(training$wage,g=3)
library(Hmisc)
cutWage <- cut2(training$wage,g=3)
table(cutWage)
p1 <- qplot(cutWage,age, data=training,fill=cutWage,
geom=c("boxplot"))
p1
p2 <- qplot(cutWage,age, data=training,fill=cutWage,
geom=c("boxplot","jitter"))
grid.arrange(p1,p2,ncol=2)
t1 <- table(cutWage,training$jobclass)
t1
prop.table(t1,1)
qplot(wage,colour=education,data=training,geom="density")
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
hist(training$capitalAve,main="",xlab="ave. capital run length")
mean(training$capitalAve)
sd(training$capitalAve)
trainCapAve <- training$capitalAve
trainCapAveS <- (trainCapAve  - mean(trainCapAve))/sd(trainCapAve)
mean(trainCapAveS)
sd(trainCapAveS)
testCapAveS <- (testCapAve  - mean(trainCapAve))/sd(trainCapAve)
testCapAve <- testing$capitalAve
testCapAveS <- (testCapAve  - mean(trainCapAve))/sd(trainCapAve)
mean(testCapAveS)
sd(testCapAveS)
preObj <- preProcess(training[,-58],method=c("center","scale"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
mean(trainCapAveS)
sd(trainCapAveS)
preObj <- preProcess(training[,-58],method=c("center","scale"))
testCapAveS <- predict(preObj,testing[,-58])$capitalAve
mean(testCapAveS)
sd(testCapAveS)
set.seed(32343)
modelFit <- train(type ~.,data=training,
preProcess=c("center","scale"),method="glm")
preObj <- preProcess(training[,-58],method=c("BoxCox"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
par(mfrow=c(1,2)); hist(trainCapAveS); qqnorm(trainCapAveS)
set.seed(13343)
training$capAve <- training$capitalAve
selectNA <- rbinom(dim(training)[1],size=1,prob=0.05)==1
training$capAve[selectNA] <- NA
preObj <- preProcess(training[,-58],method="knnImpute")
capAve <- predict(preObj,training[,-58])$capAve
capAveTruth <- training$capitalAve
capAveTruth <- (capAveTruth-mean(capAveTruth))/sd(capAveTruth)
quantile(capAve - capAveTruth)
quantile((capAve - capAveTruth)[selectNA])
quantile((capAve - capAveTruth)[!selectNA])
http://caret.r-forge.r-project.org/preprocess.html
library(kernlab);data(spam)
spam$capitalAveSq <- spam$capitalAve^2
str(spam)
library(ISLR); library(caret); data(Wage);
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
table(training$jobclass)
dummies <- dummyVars(wage ~ jobclass,data=training)
head(predict(dummies,newdata=training))
nsv <- nearZeroVar(training,saveMetrics=TRUE)
nsv
install.packages("splines")
library(splines)
bsBasis <- bs(training$age,df=3)
bsBasis
head(bsBasis)
lm1 <- lm(wage ~ bsBasis,data=training)
plot(training$age,training$wage,pch=19,cex=0.5)
points(training$age,predict(lm1,newdata=training),col="red",pch=19,cex=0.5)
predict(bsBasis,age=testing$age)
predict(bsBasis,age=testing$age)
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
M <- abs(cor(training[,-58]))
diag(M) <- 0
which(M > 0.8,arr.ind=T)
names(spam)[c(34,32)]
plot(spam[,34],spam[,32])
names(spam)[c(34,40)]
plot(spam[,34],spam[,40])
X <- 0.71*training$num415 + 0.71*training$num857
Y <- 0.71*training$num415 - 0.71*training$num857
plot(X,Y)
smallSpam <- spam[,c(34,32)]
prComp <- prcomp(smallSpam)
plot(prComp$x[,1],prComp$x[,2])
prComp
prComp$rotation
typeColor <- ((spam$type=="spam")*1 + 1)
prComp <- prcomp(log10(spam[,-58]+1))
plot(prComp$x[,1],prComp$x[,2],col=typeColor,xlab="PC1",ylab="PC2")
typeColor
preProc <- preProcess(log10(spam[,-58]+1),method="pca",pcaComp=2)
spamPC <- predict(preProc,log10(spam[,-58]+1))
plot(spamPC[,1],spamPC[,2],col=typeColor)
preProc <- preProcess(log10(training[,-58]+1),method="pca",pcaComp=2)
trainPC <- predict(preProc,log10(training[,-58]+1))
str(trainPC)
modelFit <- train(training$type ~ .,method="glm",data=trainPC)
modelFit
summary(modelFit)
testPC <- predict(preProc,log10(testing[,-58]+1))
confusionMatrix(testing$type,predict(modelFit,testPC))
modelFit <- train(training$type ~ .,method="glm",preProcess="pca",data=training)
library(caret);data(faithful); set.seed(333)
inTrain <- createDataPartition(y=faithful$waiting,
p=0.5, list=FALSE)
trainFaith <- faithful[inTrain,]; testFaith <- faithful[-inTrain,]
head(trainFaith)
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lm1 <- lm(eruptions ~ waiting,data=trainFaith)
summary(lm1)
lines(trainFaith$waiting,lm1$fitted,lwd=3)
coef(lm1)[1] + coef(lm1)[2]*80
newdata <- data.frame(waiting=80)
predict(lm1,newdata)
par(mfrow=c(1,2))
plot(trainFaith$waiting,trainFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lines(trainFaith$waiting,predict(lm1),lwd=3)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue",xlab="Waiting",ylab="Duration")
lines(testFaith$waiting,predict(lm1,newdata=testFaith),lwd=3)
sqrt(sum((lm1$fitted-trainFaith$eruptions)^2))
mean(lm1$fitted)
sqrt(sum((predict(lm1,newdata=testFaith)-testFaith$eruptions)^2))
pred1 <- predict(lm1,newdata=testFaith,interval="prediction")
matlines(testFaith$waiting[ord],pred1[ord,],type="l",,col=c(1,2,2),lty = c(1,1,1), lwd=3)
ord <- order(testFaith$waiting)
plot(testFaith$waiting,testFaith$eruptions,pch=19,col="blue")
matlines(testFaith$waiting[ord],pred1[ord,],type="l",,col=c(1,2,2),lty = c(1,1,1), lwd=3)
modFit <- train(eruptions ~ waiting,data=trainFaith,method="lm")
summary(modFit$finalModel)
?matlines
library(ISLR); library(ggplot2); library(caret);
data(Wage); Wage <- subset(Wage,select=-c(logwage))
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
dim(training); dim(testing)
featurePlot(x=training[,c("age","education","jobclass")],
y = training$wage,
plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,colour=jobclass,data=training)
qplot(age,wage,colour=education,data=training)
modFit<- train(wage ~ age + jobclass + education,
method = "lm",data=training)
finMod <- modFit$finalModel
print(modFit)
plot(finMod,1,pch=19,cex=0.5,col="#00000010")
par(mfrow = c(1,1))
plot(finMod,1,pch=19,cex=0.5,col="#00000010")
qplot(finMod$fitted,finMod$residuals,colour=race,data=training)
plot(finMod$residuals,pch=19)
pred <- predict(modFit, testing)
qplot(wage,pred,colour=year,data=testing)
modFitAll<- train(wage ~ .,data=training,method="lm")
pred <- predict(modFitAll, testing)
qplot(wage,pred,data=testing)
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
?createDataPartition
adData = data.frame(diagnosis,predictors)
adData
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
dim(training)
dim(testing)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
createDataPartition(mixtures$CompressiveStrength, p = 3/4)
createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
plot(finMod$residuals,pch=19)
str(training)
qplot(CompressiveStrength ~ ;)
qplot(CompressiveStrength ~ ., data=concrete)
qplot(concrete)
library(ISLR); library(ggplot2); library(caret);
data(Wage); Wage <- subset(Wage,select=-c(logwage))
summary(Wage)
inTrain <- createDataPartition(y=Wage$wage,
p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
featurePlot(x=training[,c("age","education","jobclass")],
y = training$wage,
plot="pairs")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
featurePlot(x=training[,-9],y=training[,9])
featurePlot(x=training[,-9],y=training[,9],plot="pairs")
featurePlot(x=training[,-9],y=training[,9])
cor(training)
plot(training[,9])
qplot(training[,9])
qplot(training[,9],geom=points)
qplot(training[,9],geom="points")
qplot(training[,9],geom="point")
qplot(training[,9])
ggplot(aes(x=training[,9])) -> g
ggplot(aes(y=training[,9])) -> g
ggplot(aes(training[,9])) -> g
training[,9]
class(training[,9])
plot(training[,9])
qplot(seq_along(training[,9]),training[,9])
qplot(seq_along(training[,9]),training[,9], colour=training[,1])
library(Hmsic)
library(Hmidc)
library(Hmisc)
?cut2
str(training)
cut2(training[,3],4) -> training[,3]
str(training)
qplot(seq_along(training[,9]),training[,9], colour=training[,3])
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,
]
cut2(training[,3],4)
str(training)
?cut2
cut2(training[,3],g=3)
cut2(training[,3],g=4) -> training[,3]
qplot(seq_along(training[,9]),training[,9], colour=training[,3])
cut2(training[,3],g=5) -> training[,3]
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
cut2(training[,3],g=5) -> training[,3]
qplot(seq_along(training[,9]),training[,9], colour=training[,3])
str(cement)
str(training)
qplot(seq_along(training[,9]),training[,9], colour=training[,8])
cut2(training[,8],g=5) -> training[,8]
qplot(seq_along(training[,9]),training[,9], colour=training[,8])
cut2(training[,4],g=5) -> training[,4]
qplot(seq_along(training[,4]),training[,9], colour=training[,4])
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,
]
hist(training[,5])
density(training[,5])
plot(density(training[,5]))
hist(training[,5])
hist(log(training[,5])
)
hist(log10(training[,5]))
hist(log10(training[,5])+1)
hist(log10(training[,5]+1))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
str(training)
colnames(training)
grep("^IL",colnames(training))
grep("^IL",colnames(training))-> il
?preProcess
preprocess(training[,il],method="pca")
preProcess(training[,il],method="pca")
preProcess(training[,il],method="pca",pcaCom=9)
preProcess(training[,il],method="pca",pcaCom=9) -> l
summary(l)
?prcomp
prcomp(training[,il])
prcomp(training[,il])$rotation
preProcess(training[,il],method="pca")
preProcess(training[,il],method="pca",thresh=0,8)
preProcess(training[,il],method="pca",thresh=0.8)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
grep("^IL",colnames(training))-> il
tr <- training[,il]
tr
str(training)
cbind(tr,training[,1])
cbind(tr,training[,1]) -> tr
str(tr)
?preProcess
modelFit <- train(tr[,13] ~ .,method="glm",preProcess="pca",data=tr,thresh=0.8)
modelFit <- train(tr[,13] ~ .,method="glm",data=tr)
confusionMatrix(tr[,13],predict(modelFit,testing))
confusionMatrix(testing$diagnosis,predict(modelFit,testing))
modelFit <- train(tr[,13] ~ .,method="glm",data=tr)
te <- testting[,il]
te <- testing[,il]
confusionMatrix(te$diagnosis,predict(modelFit,te))
predict(modelFit,te)
grep("^IL",colnames(training))-> il
tr <- training[,c(1,il)]
str(tr)
modelFit <- train(tr[,1] ~ .,method="glm",data=tr)
confusionMatrix(te$diagnosis,predict(modelFit,te))
te <- testing[,c(1,il)]
confusionMatrix(te$diagnosis,predict(modelFit,te))
,predict(modelFit,te)
predict(modelFit,te)
te
str(te)
modelFit <- train(tr[,1] ~ .,method="glm")
modelFit <- train(tr[,1] ~ .,method="glm",data=tr)
confusionMatrix(te$diagnosis,predict(modelFit,te))
preProc <- preProcess(tr[,-1],method="pca",thresh=0.8)
trainPC <- predict(preProc,tr[,-1])
modelFit <- train(tr[,1] ~ .,method="glm",data=trainPC)
testPC <- predict(preProc,te[,1])
testPC <- predict(preProc,te[,-1])
confusionMatrix(te[,-1],predict(modelFit,testPC))
confusionMatrix(te[,1],predict(modelFit,testPC))
modelFit <- train(tr[,1] ~ .,method="glm",data=tr)
confusionMatrix(te[,1],predict(modelFit,te))
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
modelFit <- train(training ~ .,method="glm",data=tr)
tr <- training[,il]
modelFit <- train(training[,1] ~ .,method="glm",data=tr)
confusionMatrix(testing[,1],predict(modelFit,testing))
iris
?featurePlor
?featurePlot
library(caret)
?featurePlot
featurePlot(iris[,-4]~iris[,4],plot = "ellipse")
x <- matrix(rnorm(50*5),ncol=5)
y <- factor(rep(c("A", "B"),  25)
)
featurePlot(x, y, "ellipse"
)
?featurePlot
x
y
featurePlot(iris[,-4]~iris[,4],plot = "ellipse")
featurePlot(iris[,-4],iris[,4],plot = "ellipse")
featurePlot(iris[,-4],as.factor(iris[,4]_,plot = "ellipse")
featurePlot(iris[,-4],as.factor(iris[,4]),plot = "ellipse")
str(iris)
featurePlot(iris[,-5],iris[,5],plot = "ellipse")
?featurePlot
featurePlot(iris[,-5],iris[,5],plot = "box")
?featurePlot
featurePlot(iris[,-5],iris[,5],plot = "strip")
?featurePlot
featurePlot(iris[,-5],iris[,5],plot = "strip",jitter=TRUE)
?featurePlot
featurePlot(iris[,-5],iris[,5],plot = "pairs")
iris
ggplot(iris)
library(ggplot2)
qplot(iris)
coplot(iris)
library(carret)
library(caret)
featurePlot(iris)
?featurePlot
featurePlot(iris[,-5],iris[,5])
?featurePlot
featurePlot(iris[,-5],iris[,5],"ellipse")
setwd("C:/Coursera")
setwd("C:/Coursera/BMI")
runapp()
library(shiny)
runApp()
library(knitr)
shiny::runApp()
shiny::runApp()
kable(data.frame(Status = c("Underweight","Normal","Overweight","Obese"),
BMI(kg/m2)=c("< 18.5","18.5-25","25-30","> 30")))
kable(data.frame(Status = c("Underweight","Normal","Overweight","Obese"),
BMI=c("< 18.5","18.5-25","25-30","> 30")))
data.frame(Status = c("Underweight","Normal","Overweight","Obese"),
BMI=c(18.5,6.5,5,10),id=rep("",4) )-> gr
library(ggplot2)
ggplot(data=gr,aes(x=id,y=BMI,fill=Status,width=0.1))+
geom_bar(stat="identity",position="stack",size=1)+
coord_flip()+
scale_fill_brewer(type="div",palette="OrRd",breaks=c("Underweight","Normal","Overweight","Obese"))+
scale_x_discrete(name="")+theme_bw()+theme(legend.position="top")+theme(legend.position=c(0.5,0.2))+
guides(fill=guide_legend(title=NULL,nrow=1))+
annotate("segment",y=22,x=1.2,yend=22,xend=1.04,col="orange",size=1.2, arrow  =arrow(length= unit(0.5,"cm")))+
annotate("text", label= "Your BMI",x=1.23,y=22,col="orange",size=6,fontface="bold")+
annotate("point",x=1,y=22,size=4,col="orange")
runApp()
shiny::runApp()
shiny::runApp()
shiny::runApp()
